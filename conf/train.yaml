device: cuda
use_wandb: false

mode:
  is_train: true
  train_single_image: true

train_setting:
  max_steps:  100000
  inference_steps: 100
  embedding_save_steps: 100

train_dataset:
  root: 'ImageNet2012'
  split: 'train'
  device: cuda:0
  batch_size: 32
  shuffle: true

test_dataset:
  root: 'ImageNet2012'
  split: 'test'

single_image:
  path: 'data/test1.png'

model:
  # encoder_type: 'pure_index'
  # decoder_type: 'decode_index'
  encoder_type: 'pure_embedding'
  decoder_type: 'decoder_embedding'

  pure_embedding:
    device: ${device}
    query_num: 77
    feature_dim: 1024
    training_params:
      lr: 0.03
      min_betas: 0.9
      max_betas: 0.99
      weight_decay: 0.01
      warmup_steps: 10000
      T_mult: 1
      eta_min: 0.0003

  pure_index:
    device: ${device}
    query_num: 75
    feature_dim: 49406
    training_params:
      lr: 0.3
      min_betas: 0.9
      max_betas: 0.999
      weight_decay: 0.01
      warmup_steps: 10000
      T_mult: 1
      eta_min: 0.0003

  encoder_embedding:
    device: ${device}
    clip_model_name: 'coca_ViT-L-14'
    clip_pretrained_model_name_or_path: 'laion/mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin'
    num_transformer_block: 5
    query_num: 77
    query_dim: 768
    feature_dim: 1024
    block:
      input_dim: 768
      num_heads: 8
      mlp_hidden_features: 128
    training_params:
      lr: 0.0005
      min_betas: 0.9
      max_betas: 0.99
      weight_decay: 0.01
      warmup_steps: 10000
      T_mult: 1
      eta_min: 0.000005

  encoder_index:
    device: ${device}
    clip_model_name: 'coca_ViT-L-14'
    clip_pretrained_model_name_or_path: 'laion/mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin'
    num_transformer_block: 5
    query_num: 77
    query_dim: 768
    feature_dim: 49406
    block:
      input_dim: 768
      num_heads: 8
      mlp_hidden_features: 128
    training_params:
      lr: 0.0005
      min_betas: 0.9
      max_betas: 0.99
      weight_decay: 0.01
      warmup_steps: 10000
      T_mult: 1
      eta_min: 0.000005

  decoder_embedding:
    device: ${device}
    unet_pretrained_model_name_or_path: 'stabilityai/stable-diffusion-2-1-base'
    half_precision_weights: False
    do_classifier_free_guidance: False

  decode_index:
    device: ${device}
    unet_pretrained_model_name_or_path: 'stabilityai/stable-diffusion-2-1-base'
    half_precision_weights: False
    do_classifier_free_guidance: True

  decode_index_small:
    device: ${device}
    unet_pretrained_model_name_or_path: 'stabilityai/stable-diffusion-2-1-base'
    half_precision_weights: False
    do_classifier_free_guidance: True
    whole_token_lens: 49408
    small_token_lens: 1000
    feature_dim: 1024
    gt_prompt: 'an davilishlishblog closeup berries jar through largerefrerefrejar glass jar eachother glass on an on peach hardwood closeup glass homemade osmixed glass jar called relating called an oranges fruit shown slices eachother containing relating an orange orange slices slices between black grapes open chunks orange oranges and berry blackblueberry consist though towards pink closeup facing that background pink wall background pink pink wall wall closeup chia grapes recipe'